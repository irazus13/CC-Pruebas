---
title: "Bias-Mitigated AI as a Foundation for Resilient and Effective Health Systems."
description: "Artificial intelligence (AI) is rapidly reshaping the landscape of health care, from clinical diagnostics and disease surveillance to the prediction of individual health risks. Yet, its immense promise will only materialize if the tools we deploy wor..."
date: "2026-02-23"
category: "ia-medicina"
pubmedId: "41730169"
author: "Jarbas Barbosa da Silva, Maureen Birminghamm, Ana Rivi&#xe8;re Cinnamond et al."
tags: ["AI", "artificial intelligence", "bias in artificial intelligence", "digital health", "primary health care"]
---

## Resumen

Artificial intelligence (AI) is rapidly reshaping the landscape of health care, from clinical diagnostics and disease surveillance to the prediction of individual health risks. Yet, its immense promise will only materialize if the tools we deploy work for everyone. Algorithms trained on incomplete or biased datasets risk embedding historical health disparities and can replicate patterns of uneven data representation, thereby limiting accuracy and generalizability across population groups. Addressing algorithmic bias should be treated as a core health quality standard, comparable in importance to safety and efficacy evaluations, to ensure consistent performance across all segments of the population. This paper aims to frame algorithmic bias in health-related AI as a quality, safety, and governance challenge for health systems rather than solely a technical problem for developers. It aims to inform policymakers, regulators, health system leaders, and developers by translating existing scientific evidence and regulatory guidance into operational governance considerations, with particular attention to the realities of low- and middle-income settings in the region of the Americas. This paper synthesizes existing knowledge and institutional experience into a practical, regionally grounded policy perspective. To operationalize this perspective, this paper first outlines the main forms of algorithmic bias relevant to health systems-including representation, measurement, aggregation, and deployment biases-and illustrates how each can emerge across the AI lifecycle. It then situates these technical challenges within the broader digital health context, where structural, commercial, and social dynamics may amplify inequities. This paper discusses the implications of biased data for emerging areas such as precision medicine before proposing a governance-oriented framework for bias mitigation that spans design, validation, deployment, and postmarket monitoring. It concludes with priority governance actions for policymakers, regulators, and health system leaders to embed fairness as a measurable component of health system performance.

## Información del artículo

- **Revista:** JMIR public health and surveillance
- **Fecha de publicación:** 2026-02-23
- **Autores:** Jarbas Barbosa da Silva, Maureen Birminghamm, Ana Rivi&#xe8;re Cinnamond, Eldonna Boisson, Mary Lou Valdez
- **DOI:** [10.2196/88457](https://doi.org/10.2196/88457)
- **PubMed ID:** [41730169](https://pubmed.ncbi.nlm.nih.gov/41730169/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41730169/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
