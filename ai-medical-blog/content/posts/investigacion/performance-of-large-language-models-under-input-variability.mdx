---
title: "Performance of Large Language Models Under Input Variability in Health Care Applications: Dataset Development and Experimental Evaluation."
description: "Large language models (LLMs) are increasingly integrated into health care, where they contribute to patient care, administrative efficiency, and clinical decision-making. Despite their growing role, the ability of LLMs to handle imper..."
date: "2026-02-20"
category: "investigacion"
pubmedId: "41719488"
author: "Saubhagya Joshi, Monjil Mehta, Sarjak Maniar et al."
tags: ["dataset", "error analysis", "health informatics", "large language models", "robustness"]
---

## Resumen

**BACKGROUND:** Large language models (LLMs) are increasingly integrated into health care, where they contribute to patient care, administrative efficiency, and clinical decision-making. Despite their growing role, the ability of LLMs to handle imperfect inputs remains underexplored. These imperfections, which are common in clinical documentation and patient-generated data, may affect model reliability. **OBJECTIVE:** This study investigates the impact of input perturbations on LLM performance across three dimensions: (1) overall effectiveness in different health-related applications, (2) comparative effects of different types and levels of perturbations, and (3) differential impact of perturbations on health-related terms versus non-health-related terms. **METHODS:** We systematically evaluate 3 LLMs on 3 health-related tasks using a novel dataset containing 3 types of human-like variations (redaction, homophones, and typographical errors) at different perturbation levels. **RESULTS:** Contrary to expectations, LLMs demonstrate notable robustness to common variations, and in more than half of the cases (151/270, 55.92%), the performance was stable or improved. In some cases (38/270, 14.07%), variations resulted in an increased performance, especially when dealing with lower perturbation levels. Redactions, often stemming from privacy concerns or cognitive lapses, are more detrimental than other variations. **CONCLUSIONS:** Our findings highlight the need for health care applications powered by LLMs to be designed with input variability in mind. Robustness to noisy or imperfect inputs is essential for maintaining reliability in real-world clinical settings, where data quality can vary widely. By identifying specific vulnerabilities and strengths, this study provides actionable insights for improving model resilience and guiding the development of safer, more effective artificial intelligence tools in health care. The accompanying dataset offers a valuable resource for further research into LLM performance under diverse conditions.

## Información del artículo

- **Revista:** JMIR AI
- **Fecha de publicación:** 2026-02-20
- **Autores:** Saubhagya Joshi, Monjil Mehta, Sarjak Maniar, Mengqian Wang, Vivek Kumar Singh
- **DOI:** [10.2196/83640](https://doi.org/10.2196/83640)
- **PubMed ID:** [41719488](https://pubmed.ncbi.nlm.nih.gov/41719488/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41719488/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
