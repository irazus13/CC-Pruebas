---
title: "AdaptiveInvolutionNet: Spatially-adaptive involution with channel-wise attention for breast MRI tumor classification."
description: "Early and accurate classification of breast tumors from MRI scans is essential for improving patient outcomes. However, a key limitation of conventional deep learning models, such as Convolutional Neural Networks (CNNs), is their diff..."
date: "2026-01-01"
category: "ia-radiologia"
pubmedId: "41712600"
author: "Saeed Alqahtani, Khaled Alqahtani, Faisal Alshomrani et al."
tags: []
---

## Resumen

**BACKGROUND:** Early and accurate classification of breast tumors from MRI scans is essential for improving patient outcomes. However, a key limitation of conventional deep learning models, such as Convolutional Neural Networks (CNNs), is their difficulty in capturing the subtle, spatially variant features that are crucial for precise medical image interpretation. **OBJECTIVE:** To address this limitation, we propose a novel deep learning framework called AdaptiveInvolutionNet (AIN). This hybrid architecture is specifically designed to improve discriminative feature learning for breast tumor classification by integrating two key mechanisms: spatially-adaptive involution layers and channel-wise attention. **METHODS:** Our AIN model employs a unique strategy for feature extraction. In its early layers, it utilizes spatially-adaptive involution kernels, which are highly effective at capturing fine-grained, localized features. As the network deepens, it transitions to conventional convolutions to maintain computational efficiency. To further enhance its diagnostic capabilities, we have embedded channel-wise attention mechanisms (specifically, squeeze-and-excitation modules) within the residual connections of the network. This allows the model to dynamically and selectively amplify diagnostically relevant features while suppressing less important ones. The model was rigorously trained and evaluated on a large, balanced dataset of 6,000 breast MRI images (3,000 benign, 3,000 malignant) using a robust five-fold cross-validation protocol. **RESULTS:** AIN demonstrated superior performance, achieving a high test accuracy of 97%. This performance was consistent and reliable across all folds, with an average accuracy of 96% (&#xb1; 1%). The model also showed strong agreement with true labels, indicated by a high Cohen's Kappa score of 0.93 (&#xb1; 0.01), and produced well-calibrated, trustworthy predictions with a low Brier score of just 0.0241. **CONCLUSION:** By successfully uniting an adaptive spatial feature extraction method with powerful attention mechanisms, AIN represents a significant advancement in medical image analysis. Its high accuracy, robust generalization, and consistent reliability demonstrate a strong potential for it to serve as a valuable and dependable computer-aided diagnostic tool for breast cancer detection in clinical settings.

## Información del artículo

- **Revista:** PloS one
- **Fecha de publicación:** 2026-01-01
- **Autores:** Saeed Alqahtani, Khaled Alqahtani, Faisal Alshomrani, Khaled AlQahtani
- **DOI:** [10.1371/journal.pone.0340808](https://doi.org/10.1371/journal.pone.0340808)
- **PubMed ID:** [41712600](https://pubmed.ncbi.nlm.nih.gov/41712600/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41712600/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
