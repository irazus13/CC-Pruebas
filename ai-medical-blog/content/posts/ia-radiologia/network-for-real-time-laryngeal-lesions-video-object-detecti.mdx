---
title: "Network for Real-time Laryngeal Lesions Video Object Detection."
description: "Early and accurate diagnosis of nasopharyngeal-laryngeal tumors is critical for improving patient prognosis. Deep learning methods have achieved significant progress in the automatic detection of lesions in static endoscopic images. However, during n..."
date: "2026-02-06"
category: "ia-radiologia"
pubmedId: "41652139"
author: "Yan Wang, Yiran Pan, Wulin Wen et al."
tags: ["Computer-aided diagnosis", "Motion blur", "Nasopharyngeal&#x2013;laryngeal endoscopy", "Video object detection"]
---

## Resumen

Early and accurate diagnosis of nasopharyngeal-laryngeal tumors is critical for improving patient prognosis. Deep learning methods have achieved significant progress in the automatic detection of lesions in static endoscopic images. However, during nasopharyngeal-laryngeal endoscopy, the quality of endoscopic videos often suffers from motion blur, uneven exposure, and reflective artifacts, which adversely affect the performance of existing static image detectors. Therefore, we propose a novel two-stage video lesion detection network, DynSTPN, to address the challenge of lesion detection in complex scenarios. First, in the prompt generation network stage, we design a dynamic prompt generator that generates discriminative prompt based on spatio-temporal feature representations of reference frames to mitigate quality degradation in inference frames. Second, at the object detection network stage, we introduce an adaptive differentiable gating mechanism to integrate reference frames' prompt information, dynamically adjusting the enhancement effect of reference frames on the inference frame. Experiments were conducted on two datasets: the self-constructed four-category nasopharyngeal-laryngeal lesion video object detection (NLLVOD) and the publicly available ImageNet VID dataset. Compared to state-of-the-art (SOTA) methods, DynSTPN achieved the best balance between detection accuracy and efficiency on the VID dataset. On the NLLVOD dataset, DynSTPN achieved a superior detection accuracy of 79.6% and speed of 29.4 FPS, meeting the real-time requirements for clinical applications. These results significantly outperform SOTA static image detector, YOLOv12-M. Experimental results demonstrate that DynSTPN effectively leverages information from video reference frames to enhance detection performance, achieving superior accuracy compared to SOTA image/video methods, thereby offering enhanced clinical applicability.

## Información del artículo

- **Revista:** Journal of imaging informatics in medicine
- **Fecha de publicación:** 2026-02-06
- **Autores:** Yan Wang, Yiran Pan, Wulin Wen, Peng Yang, Jibo Wang
- **DOI:** [10.1007/s10278-026-01855-w](https://doi.org/10.1007/s10278-026-01855-w)
- **PubMed ID:** [41652139](https://pubmed.ncbi.nlm.nih.gov/41652139/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41652139/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
