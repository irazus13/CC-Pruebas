---
title: "Masked Image Modeling for Generalizable Organelle Segmentation in Volume EM."
description: "Accurate segmentation of organelles in electron microscopy (EM) volumes is essential for understanding intracellular organization. While promising, deep learning-based methods could be unstable and unreliable without sufficient annotations. Masked im..."
date: "2026-02-24"
category: "ia-radiologia"
pubmedId: "41734129"
author: "Yanchao Zhang, Hao Zhai, Jinyue Guo et al."
tags: []
---

## Resumen

Accurate segmentation of organelles in electron microscopy (EM) volumes is essential for understanding intracellular organization. While promising, deep learning-based methods could be unstable and unreliable without sufficient annotations. Masked image modeling (MIM), a powerful pretraining technique, has proven effective in enhancing segmentation by extracting meaningful representations from large-scale unlabeled data. However, random masking strategies in classic MIMs could overlook the unique structural patterns of organelles and the spatial redundancy inherent in EM volumes, thus limiting pretraining efficiency. To address this issue, we propose OrgMIM, a dual-branch MIM framework that integrates complementary masking strategies to capture critical subcellular semantics and learn organelle-specific representations from EM data. Specifically, one branch is guided by static structural priors, leveraging visual foundation models to generate affinity maps that indicate organelle membranes as masking candidates. The other is driven by dynamic reconstruction feedback, using a self-guidance mechanism to compute average loss maps that highlight intricate organelle patterns for heuristic masking. Moreover, cross-branch consistency regularization is introduced for reliable representation learning across sparse semantic contexts. To support large-scale pretraining, we construct IsoOrg-1K, the first organelle-centric 3D EM dataset, comprising 928 informative volumes and over 120 billion voxels. Extensive evaluations on three public EM datasets with varied resolutions and appearances validate the superior performance of OrgMIM. Notably, OrgMIM pretraining on IsoOrg-1K boosts mIoU by 28.78% over training from scratch on the CMCC dataset with a Transformer-based model. All datasets, source codes, and pretrained weights are available at https://github.com/yanchaoz/OrgMIM.

## Información del artículo

- **Revista:** IEEE transactions on medical imaging
- **Fecha de publicación:** 2026-02-24
- **Autores:** Yanchao Zhang, Hao Zhai, Jinyue Guo, Zhenchen Li, Jing Liu
- **DOI:** [10.1109/TMI.2026.3667612](https://doi.org/10.1109/TMI.2026.3667612)
- **PubMed ID:** [41734129](https://pubmed.ncbi.nlm.nih.gov/41734129/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41734129/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
