---
title: "Malpractice in the machine age: Legal and ethical responses to machine learning in medical imaging."
description: "Artificial intelligence (AI) and machine learning (ML) are increasingly integrated into diagnostic imaging. This review examines how AI adoption affects malpractice risk, the legal standard of care, liability distribution, and informe..."
date: "2026-02-06"
category: "ia-odontologia"
pubmedId: "41653871"
author: "M T Chau, K M Spuur, S White et al."
tags: ["Artificial Intelligence", "Informed consent", "Liability attribution", "Machine learning", "Malpractice"]
---

## Resumen

**OBJECTIVES:** Artificial intelligence (AI) and machine learning (ML) are increasingly integrated into diagnostic imaging. This review examines how AI adoption affects malpractice risk, the legal standard of care, liability distribution, and informed consent. It also evaluates regulatory developments and ethical concerns, including explicability, autonomy, and professional accountability. **KEY FINDINGS:** AI-supported image interpretation can improve diagnostic accuracy and efficiency. Its integration is reshaping expectations of reasonable clinical practice, with the potential for negligence claims both when clinicians fail to use validated systems and when they rely on insufficiently tested tools. Liability is uncertain because diagnostic responsibility is distributed across clinicians, healthcare organisations, and developers. Existing negligence frameworks assume human reasoning and struggle to accommodate opaque algorithmic decision-making, limiting courts' ability to assess whether AI-assisted diagnoses meet accepted standards. "Black box" models heighten automation bias, hinder legal scrutiny of error, and complicate professional accountability. Informed consent case law suggests AI involvement should be disclosed when it introduces material differences in risk or outcome, although this remains inconsistently applied. Ethical challenges include threats to patient trust, potential clinician deskilling, and reduced transparency in clinical communication. Regulatory initiatives such as the European Union's General Data Protection Regulation and AI Act move toward clearer governance through requirements for data quality, human oversight, and post-market monitoring, yet explicit malpractice guidance remains under-developed globally. **CONCLUSION:** Traditional legal and ethical frameworks insufficiently address accountability for AI-driven diagnostic errors. Clarifying responsibility, decision authority, and validation requirements is essential to safeguard patient safety and clinician protection. **IMPLICATIONS FOR PRACTICE:** Clinical protocols should specify approved use cases, oversight expectations, documentation of AI involvement, and management of clinician-algorithm disagreement. Training should support critical review of outputs to mitigate automation bias.

## Información del artículo

- **Revista:** Radiography (London, England : 1995)
- **Fecha de publicación:** 2026-02-06
- **Autores:** M T Chau, K M Spuur, S White, A Pyper, M Crossman
- **DOI:** [10.1016/j.radi.2026.103339](https://doi.org/10.1016/j.radi.2026.103339)
- **PubMed ID:** [41653871](https://pubmed.ncbi.nlm.nih.gov/41653871/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41653871/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
