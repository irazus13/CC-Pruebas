---
title: "A Comparative Study of Generative Artificial Intelligence Tools for Human Bone Learning."
description: "The aim of this study was to evaluate the effectiveness of three different generative AI tools, ChatGPT-4o, Claude 3.7 Sonnet, and Gemini 2.0 Flash, with a specific focus on their accuracy and response consistency in supporting self-directed learning..."
date: "2026-02-27"
category: "ia-odontologia"
pubmedId: "41761446"
author: "Wachirawit Sirirat, Paak Rewthamrongsris, Kritchai Bespinyowong et al."
tags: ["dental education", "dentistry", "generative artificial intelligence", "human anatomy", "identification"]
---

## Resumen

The aim of this study was to evaluate the effectiveness of three different generative AI tools, ChatGPT-4o, Claude 3.7 Sonnet, and Gemini 2.0 Flash, with a specific focus on their accuracy and response consistency in supporting self-directed learning in human skeletal anatomy. A total of 143 human skeletal specimens were selected for evaluation. Bone specimens from different donors were photographed to represent each structure, resulting in a total of 715 images. Four types of questions were generated to assess each AI model's ability to identify anatomical features. Responses were categorized into four groups: correct, incorrect, could not be specified, and not analyzable. For consistency assessment, 105 photographs were randomly selected from the total image set, and each was submitted to the three models independently on five separate occasions. The number of identical responses out of five was recorded for each model. ChatGPT-4o achieved the highest overall accuracy at 44.75%, significantly higher than the other two generative AI tools. Based on the coefficient scores calculated using Cohen's &#x3ba;, the majority of outcomes demonstrated levels of agreement ranging from slight to fair across the three pairs of tools compared. Gemini 2.0 Flash was the only model that produced responses classified as not analyzable. It also achieved the highest proportion of identical responses across five trials, at 62.86%. Claude 3.7 Sonnet showed the highest proportion of inconsistent responses. These findings suggest that the generative AI models evaluated lack the reliability required for anatomy education and should be used with caution due to their high propensity to generate inaccurate information.

## Información del artículo

- **Revista:** Clinical anatomy (New York, N.Y.)
- **Fecha de publicación:** 2026-02-27
- **Autores:** Wachirawit Sirirat, Paak Rewthamrongsris, Kritchai Bespinyowong, Zohaib Khurshid, Lakshman Samaranayake
- **DOI:** [10.1002/ca.70104](https://doi.org/10.1002/ca.70104)
- **PubMed ID:** [41761446](https://pubmed.ncbi.nlm.nih.gov/41761446/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41761446/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
