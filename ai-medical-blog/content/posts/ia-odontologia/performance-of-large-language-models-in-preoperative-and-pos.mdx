---
title: "Performance of large language models in preoperative and postoperative counselling for aesthetic facial procedures."
description: "Large language models (LLMs) are increasingly used in healthcare, but their role in aesthetic surgical procedures remains unexplored. These interventions present unique challenges, marked by high patient expectations, emotionally charged decision-mak..."
date: "2026-01-07"
category: "ia-odontologia"
pubmedId: "41633924"
author: "Bruce Kepler Frutuoso Maia, Everton Freitas de Morais, Thiago de Santana Santos et al."
tags: ["Aesthetic medicine", "Artificial intelligence in healthcare", "Chatbots", "Large language models"]
---

## Resumen

Large language models (LLMs) are increasingly used in healthcare, but their role in aesthetic surgical procedures remains unexplored. These interventions present unique challenges, marked by high patient expectations, emotionally charged decision-making, and subtle yet impactful outcomes on self-perception and psychosocial health. This cross-sectional in silico study evaluated the performance of ChatGPT-4 (OpenAI, 2025), DeepSeek V3 (DeepSeek AI/High-Flyer, 2025), and Gemini 2.5 Pro Experimental (Google, 2025) in preoperative and postoperative counselling for aesthetic facial surgery. Twenty-six standardised patient-oriented questions were submitted, and the anonymised responses of the chatbots were independently assessed by two calibrated oral and maxillofacial surgeons across four domains: accuracy, empathy, readability (Flesch-Kincaid Reading Ease (FKRE) and Grade Level (FKGL)), and referencing reliability (including the identification of fabricated or non-verifiable citations, a phenomenon referred to as "hallucination" in LLM outputs). Statistical tests included Kruskal-Wallis, Mann-Whitney U with Bonferroni correction, Spearman correlation, and chi-squared. DeepSeek achieved the highest accuracy (4.77 (0.51), p&#xa0;=&#xa0;0.0078) and readability (FKRE 2.92 (0.27), p&#xa0;&lt;&#xa0;0.00001), while Gemini outperformed in empathy (4.08 (0.89), p&#xa0;&lt;&#xa0;0.001). GPT-4 produced the most hallucinated citations (36%) compared with Gemini (14%) and DeepSeek (8.8%) (p&#xa0;&lt;&#xa0;0.00001). A negative correlation between empathy and readability (r&#xa0;=&#xa0;-0.34, p&#xa0;=&#xa0;0.002) suggested a trade-off between affective tone and accessibility. Overall, LLMs generated satisfactory counselling responses with distinct performance profiles, supporting their potential in patient-centred communication while reinforcing the need for human oversight.

## Información del artículo

- **Revista:** The British journal of oral &amp; maxillofacial surgery
- **Fecha de publicación:** 2026-01-07
- **Autores:** Bruce Kepler Frutuoso Maia, Everton Freitas de Morais, Thiago de Santana Santos, Lu&#xed;s Eduardo Charles Pagotto
- **DOI:** [10.1016/j.bjoms.2026.01.002](https://doi.org/10.1016/j.bjoms.2026.01.002)
- **PubMed ID:** [41633924](https://pubmed.ncbi.nlm.nih.gov/41633924/)

## Referencias

Este artículo fue obtenido automáticamente desde [PubMed](https://pubmed.ncbi.nlm.nih.gov/41633924/), la base de datos de literatura biomédica del National Center for Biotechnology Information (NCBI).
